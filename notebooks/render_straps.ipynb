{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/kristijan/kristijan-hdd-ex/ShapeFromImages/.venv/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch 1.4.0\n",
      "CUDA available\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "verbosity = 2\n",
    "if verbosity > 0:\n",
    "    print(f\"Torch {torch.__version__}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA available\")\n",
    "    else:\n",
    "        print(\"CUDA unavailable\")\n",
    "    print(f\"Device: {device}\")\n",
    "import sys\n",
    "REPO_DIR = '/media/kristijan/kristijan-hdd-ex/ShapeFromImages/'\n",
    "sys.path.append(REPO_DIR)\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "from models.smpl_official import SMPL\n",
    "\n",
    "import config\n",
    "\n",
    "from data.synthetic_training_dataset import SyntheticTrainingDataset\n",
    "\n",
    "from renderers.nmr_renderer import NMRRenderer\n",
    "\n",
    "from utils.cam_utils import get_intrinsics_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ResNet in channels: 18\n",
      "ResNet layers: 18\n",
      "IEF Num iters: 3\n"
     ]
    }
   ],
   "source": [
    "resnet_in_channels = 1 + 17  # single-channel silhouette + 17 joint heatmaps\n",
    "resnet_layers = 18\n",
    "ief_iters = 3\n",
    "print(\"\\nResNet in channels:\", resnet_in_channels)\n",
    "print(\"ResNet layers:\", resnet_layers)\n",
    "print(\"IEF Num iters:\", ief_iters)\n",
    "\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Paths -----------------------\n",
    "# Path to npz with training data.\n",
    "#train_path = 'data/amass_up3d_3dpw_train.npz'\n",
    "# Path to npz with validation data.\n",
    "#val_path = 'data/up3d_3dpw_val.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Not needed because I have fixed poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/amass_up3d_3dpw_train.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_333641/3712342689.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSyntheticTrainingDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpz_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSyntheticTrainingDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpz_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_val_monitor_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training examples found:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation examples found:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/kristijan/kristijan-hdd-ex/ShapeFromImages/data/synthetic_training_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, npz_path, params_from)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mparams_from\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h36m'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'up3d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'3dpw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'not_amass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpz_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fnames'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'poses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/kristijan/kristijan-hdd-ex/ShapeFromImages/.venv/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/amass_up3d_3dpw_train.npz'"
     ]
    }
   ],
   "source": [
    "#train_dataset = SyntheticTrainingDataset(npz_path=train_path, params_from='all')\n",
    "#val_dataset = SyntheticTrainingDataset(npz_path=val_path, params_from='all')\n",
    "#train_val_monitor_datasets = [train_dataset, val_dataset]\n",
    "#print(\"Training examples found:\", len(train_dataset))\n",
    "#print(\"Validation examples found:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMPL Model\n",
    "NOTE: Run this only once, didn't figure out why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'models.smpl_official.SMPL'>\n"
     ]
    }
   ],
   "source": [
    "smpl_model_dir = os.path.join(REPO_DIR, config.SMPL_MODEL_DIR)\n",
    "\n",
    "smpl_model = SMPL(smpl_model_dir, num_betas=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMRRenderer(\n",
       "  (renderer): Renderer()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Camera and NMR part/silhouette renderer\n",
    "# Assuming camera rotation is identity (since it is dealt with by global_orients in SMPL)\n",
    "mean_cam_t = np.array([0., 0.2, 42.])\n",
    "mean_cam_t = torch.from_numpy(mean_cam_t).float().to(device)\n",
    "mean_cam_t = mean_cam_t[None, :].expand(batch_size, -1)\n",
    "cam_K = get_intrinsics_matrix(config.REGRESSOR_IMG_WH, config.REGRESSOR_IMG_WH, config.FOCAL_LENGTH)\n",
    "cam_K = torch.from_numpy(cam_K.astype(np.float32)).to(device)\n",
    "cam_K = cam_K[None, :, :].expand(batch_size, -1, -1)\n",
    "cam_R = torch.eye(3).to(device)\n",
    "cam_R = cam_R[None, :, :].expand(batch_size, -1, -1)\n",
    "nmr_parts_renderer = NMRRenderer(batch_size,\n",
    "                                 cam_K,\n",
    "                                 cam_R,\n",
    "                                 config.REGRESSOR_IMG_WH,\n",
    "                                 rend_parts_seg=True)\n",
    "\n",
    "smpl_model.to(device)\n",
    "nmr_parts_renderer.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Augmentation -----------------------\n",
    "# SMPL\n",
    "augment_shape = True\n",
    "delta_betas_distribution = 'normal'\n",
    "delta_betas_std_vector = torch.tensor([1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5],\n",
    "                                      device=device).float()  # used if delta_betas_distribution is 'normal'\n",
    "delta_betas_range = [-3., 3.]  # used if delta_betas_distribution is 'uniform'\n",
    "smpl_augment_params = {'augment_shape': augment_shape,\n",
    "                       'delta_betas_distribution': delta_betas_distribution,\n",
    "                       'delta_betas_std_vector': delta_betas_std_vector,\n",
    "                       'delta_betas_range': delta_betas_range}\n",
    "# Camera\n",
    "xy_std = 0.05\n",
    "delta_z_range = [-5, 5]\n",
    "cam_augment_params = {'xy_std': xy_std,\n",
    "                      'delta_z_range': delta_z_range}\n",
    "# BBox\n",
    "crop_input = True\n",
    "mean_scale_factor = 1.2\n",
    "delta_scale_range = [-0.2, 0.2]\n",
    "delta_centre_range = [-5, 5]\n",
    "bbox_augment_params = {'crop_input': crop_input,\n",
    "                       'mean_scale_factor': mean_scale_factor,\n",
    "                       'delta_scale_range': delta_scale_range,\n",
    "                       'delta_centre_range': delta_centre_range}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90a6017628d5cdce0d44e5e7bbd52e05eb69906c7b94fdb212071e3d1603a9ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
